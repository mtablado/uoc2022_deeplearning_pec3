{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2021-2_M2.875_PEC3_Enunciado.ipynb","provenance":[],"collapsed_sections":["YO1mZRrP4FT2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[""],"metadata":{"id":"vzfQ__zQ62mC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YO1mZRrP4FT2"},"source":["<div style=\"width: 100%; clear: both;\">\n","<div style=\"float: left; width: 50%;\">\n","<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n","</div>\n","<div style=\"float: right; width: 50%;\">\n","<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · PEC3\n","</p>\n","<p style=\"margin: 0; text-align:right;\">2021-2 · Máster universitario en Ciencia de datos (Data science)</p>\n","<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n","</div>\n","</div>\n","<div style=\"width:100%;\">&nbsp;</div>\n","\n","\n","# PEC 3: Recurrent Neural Networks\n","\n","En esta práctica implementaremos redes neuronales recurrentes para generar música.\n","\n","**Importante: La entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"]},{"cell_type":"markdown","source":["# 0. Contexto y referencias"],"metadata":{"id":"8rXYszqtPC3X"}},{"cell_type":"markdown","source":["Esta PEC está basada en el siguiente [artículo de investigación](https://arxiv.org/pdf/1711.07682.pdf), aunque por motivos de extensión no podremos pasar por todos los puntos del artículo.\n","\n","La primera etapa de esta PEC será leer y entender la idea general de este trabajo. El artículo os da acceso al código original con el que se ha llevado a cabo el trabajo y en el que además esta basado gran parte del código que aquí os adjuntamos, aunque por la complejidad y extensión del código no os recomendamos que sumergáis demasiado en él.\n","\n","La PEC consta de una etapa de ***interpretación de los datos*** (un paso vital en todo proyecto real), donde se pedirá reproducir una gráfica del artículo. Luego ***entrenaremos*** una red LSTM para generar acordes a partir de archivos MIDI. Finalmente, usaremos la capa de ***embedding*** de la red entrenada para hacer una proyección de los acordes en 2D y visualizar el concepto de [word2vec](https://en.wikipedia.org/wiki/Word2vec)."],"metadata":{"id":"23HcctV9PHD8"}},{"cell_type":"markdown","source":["Además de este fichero os hemos adjuntado un archivo comprimido con una estructura de datos similar a la usada en el artículo y que os recomendamos (por vuestro bien) que no modifiquéis :). Allí encontraréis una carpeta llamada *data* donde se encuentra la base de datos que usaremos y otros ficheros que os facilitamos con datos de redes ya entrenadas (en la carpeta *models*)"],"metadata":{"id":"yAJEhzrBUoNj"}},{"cell_type":"markdown","source":["# 1. Procesado de datos [2.5 pts]"],"metadata":{"id":"TNeJCTqGN6M0"}},{"cell_type":"markdown","source":["## 1.1 Importación de módulos y paquetes necesarios"],"metadata":{"id":"HFZhc-3gh3BA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kC_lb6hDNJD8"},"outputs":[],"source":["!pip install pretty_midi==0.2.8"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8Dho4VBiNX22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# añade el path a tu directorio\n","#%cd /content/drive/MyDrive/UOC PACs/PAC3/"],"metadata":{"id":"47q84NyONZf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import _pickle as pickle\n","import os\n","import sys\n","import pretty_midi as pm\n","import mido\n","from collections import Counter\n","import collections\n","import pandas as pd"],"metadata":{"id":"-aQnhJf8OVia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["importamos módulos propios (archivos .py) que podréis encontrar en la estructura de carpetas que os hemos facilitado"],"metadata":{"id":"bqTy38QPXdz8"}},{"cell_type":"code","source":["from settings import *\n","import midi_functions as mf \n","import data_processing_functions as dpf"],"metadata":{"id":"A8hOlwmbXdGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.2 Ficheros MIDI [1 pt]"],"metadata":{"id":"d457Myp0iAC6"}},{"cell_type":"markdown","source":["En esta sección vamos a entender un poco mejor la información que contiene un fichero MIDI y reproduciremos un archivo de nuestra base de datos. Para esta sección os recomendamos que le echéis un vistazo a la sección \"*Extract notes*\" del siguiente [tutorial de tensorflow](https://www.tensorflow.org/tutorials/audio/music_generation)."],"metadata":{"id":"OkBli7noiYXJ"}},{"cell_type":"markdown","source":["1.2.1 Escoger un fichero MIDI de la base de datos y crear las funciones necesarias para extraer las notas, el tiempo en que se toca cada nota, su duración y el momento en que se tocan. Este proceso se debe aplicar solo a un instrumento: **\"Acoustic Grand Piano\"**. \n","\n","*nota: Si el fichero escogido no tiene piano elegir otro fichero*"],"metadata":{"id":"QWjhouM0kHcD"}},{"cell_type":"code","source":[""],"metadata":{"id":"enL4QSw0CW2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.2.2 Modificar la funcion *plot_piano_roll* del tutorial para poder graficar el pianoroll de la canción MIDI escogida. En este caso deberemos poder indicar un tiempo máximo de la canción que queremos añadir en el pianoroll. Además, si pasamos un *max_time=-1*, se deberán graficar todas las notas de la canción"],"metadata":{"id":"bvOkNBItrqIZ"}},{"cell_type":"code","source":["def plot_piano_roll(...):\n","  pass"],"metadata":{"id":"THE0cdxNCXwH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.3 Procesado de datos [1.5 pts]"],"metadata":{"id":"Ry5uiuVywVb9"}},{"cell_type":"markdown","source":["Ahora volvemos al artículo y aplicaremos el procesado de datos. Buscar dentro del fichero *data_processing_functions.py* la función que se encarga de llevar a cabo todo el procesado de datos y llamarla desde aquí"],"metadata":{"id":"Qhk-FbIVwfYH"}},{"cell_type":"markdown","source":["1.3.1 ¿Qué hace la función *change_tempo_folder*?¿Qué bpm fija para las canciones?"],"metadata":{"id":"C_LOJsQR1WGH"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"KAP_DAD8ChAl"}},{"cell_type":"markdown","source":["1.3.2 Una vez tenemos ejecutado el procesado de datos se habrán creado muchas carpetas y muchos ficheros nuevos en la actual carpeta ***data***. Ahora usaremos algunos de estos ficheros para construir la figura 2 del artículo usando los datos procesados. Crearemos dos funciones:\n","*   my_save_histo_oct_from_midi_folder\n","*   my_midi_to_histo_oct\n","\n","basadas en las funciones ***save_histo_oct_from_midi_folder*** y ***midi_to_histo_oct*** que encontraréis en los ficheros ***midi_functions.py*** y ***data_processing_functions.py***. Ahora las modificaremos para que nos devuelvan datos para dos tipos de histogramas: uno igual a la figura 2 del artículo (apariciones VS pitch) y otro, usando el *histo_oct*, que serán datos para graficar *apariciones VS notas en cualquier octava*, es decir, el número de veces que aparece una nota (sin importar a que octava pertenezca) a lo largo de una canción."],"metadata":{"id":"l5DNt93c32tc"}},{"cell_type":"markdown","source":["\n","*indicación: Es importante entender la estructura de las variables:*\n","*   pianoroll\n","*   histo_bar\n","*   histo_oct\n","\n","*dentro de la funcion* ***midi_to_histo_oct***"],"metadata":{"id":"vHNEdanvAzLp"}},{"cell_type":"code","source":["#usa este vector como labels del segundo gráfico \n","notas_en_una_octava = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']"],"metadata":{"id":"IygIfEr3_z8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def my_save_histo_oct_from_midi_folder(...):\n","  pass\n","\n","def my_midi_to_histo_oct(...):\n","  pass"],"metadata":{"id":"PuDexJSYCjo2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.3.3 Buscar en internet sobre las escalas musicales e indicar que escala es la que más aparece en todas las canciones analizadas. ¿Cuáles dirías que son las notas más importantes de la escala?"],"metadata":{"id":"RWEqYiSwDNse"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"dz7cVn0uCkYT"}},{"cell_type":"markdown","source":["#2. LSTM para acordes [5 pts]"],"metadata":{"id":"r4r3sBgKy8bG"}},{"cell_type":"markdown","source":["El siguiente paso en el artículo es el entrenamiento de una red LSTM para la generación de acordes. Esta parte la haremos con un data set más pequeño y lo compararemos con resultados de entrenamientos previos que os faciliaremos. Primero cargamos la librerias que necesitaremos"],"metadata":{"id":"Z6wMsYrIzPMI"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense, Activation\n","from keras.layers import Embedding\n","from tensorflow.keras.optimizers import RMSprop, Adam\n","import tensorflow as tf\n","from tensorflow.compat.v1.keras.backend import set_session\n","import keras.utils\n","from keras.utils import np_utils\n","from random import shuffle\n","import progressbar\n","import time"],"metadata":{"id":"W_WNRwExGMqc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.1 Carga de datos [0.5 pts]"],"metadata":{"id":"W5pcyB6d0VIJ"}},{"cell_type":"markdown","source":["2.1.1 En la carpeta ***data*** encontraréis un fichero llamado ***dataset.pkl*** que contiene 11338 canciones de train y 3780 de test. Usando *pickle* cargar los datos y luego separar 2000 para *train* y 500 canciones para *test* en las variables: \n","*   train_set\n","*   test_set\n","\n","crea además *train_set_size* y *test_set_size*"],"metadata":{"id":"xFE6WSN70S8m"}},{"cell_type":"code","source":[""],"metadata":{"id":"b4oT9iNmCmFw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Modelo con una capa de ***Embedding*** [0.5 pts]"],"metadata":{"id":"AweMb9yv352X"}},{"cell_type":"markdown","source":["2.2.1 Ahora definiremos los parámetros de nuestra red LSTM usando los parámetros que dan en el artículo. El único cambio será en el tamaño de la red LSTM, en la que usaremos la mitad de la LSTM del artículo y número de epochs que usaremos 10 en nuestro caso"],"metadata":{"id":"-If6wor_3_YG"}},{"cell_type":"code","source":["batch_size = 1\n","step_size = 1\n","epochs = 10\n","\n","#completar\n","lstm_size = \n","learning_rate =\n","optimizer = "],"metadata":{"id":"JpqqH3X36URV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El siguiente código es para mantener la estructura de carpetas que usan en el artículo ya que hay mucho código que depende de esta estructura:"],"metadata":{"id":"WL28R7s_3f7w"}},{"cell_type":"code","source":["##--------NO TOCAR-------------------------------------------------------\n","base_path = 'models/chords/'\n","model_filetype = '.pickle'\n","\n","shuffle_train_set = True\n","bidirectional = False\n","\n","#Create model dir\n","fd = {'shifted': shifted, 'lr': learning_rate, 'emdim': chord_embedding_dim, 'opt': optimizer,\n","'bi': bidirectional, 'lstms': lstm_size, 'trainsize': train_set_size, 'testsize': test_set_size, 'samples_per_bar': samples_per_bar}\n","t = str(np.random.randint(1000,9999))\n","model_name = t+ '-Shifted_%(shifted)s_Lr_%(lr)s_EmDim_%(emdim)s_opt_%(opt)s_bi_%(bi)s_lstmsize_%(lstms)s_trainsize_%(trainsize)s_testsize_%(testsize)s_samples_per_bar%(samples_per_bar)s' % fd\n","model_path = base_path + model_name + '/'\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","##--------NO TOCAR-------------------------------------------------------\n"],"metadata":{"id":"l1diXWzq3tun"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.2.2 Finalmente definimos y compilamos la red con una capa de Embedding antes de la LSTM. Para este paso, acceder al código original del artículo y buscar en que fichero se entrena la LSTM copiar la estructura eliminando código que no es de nuestro interés"],"metadata":{"id":"PKt5WJ5d8YPb"}},{"cell_type":"code","source":[""],"metadata":{"id":"jlh6rMLuCn_Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Entrenamiento [2 pts]"],"metadata":{"id":"aMLDg6O1BNKK"}},{"cell_type":"markdown","source":["2.3.1 Siguiendo el código orginal del artículo donde se define la arquitectura de la LSTM para los acordes hay 3 funciones más:\n","*   test()\n","*   train()\n","*   save_params()\n","\n","que nos serán de ayuda para el entrenamiento, testeo y para guardar los datos sobre el modelo entrenado. Guardaremos el valor de la ***loss*** tanto para test como para train cada 500 canciones, por lo que tendremos más de un punto por epoch. Modifica, si es necesario, las funciones *test()* y *train()* para que los ficheros de *total_test* y *total_train* dejen constancia de la epoch a la que pertenecen, esto te ayudará al graficar los datos más adelante.\n","\n","Añade, antes de cada función una cabecera explicando brevemente lo que ésta hace.\n","\n","---\n","\n","*nota: comprueba que has definido todas las variables necesarias para que las* *funciones no den error en mitad del entrenamiento. Comienza usando menos datos* *para agilizar el proceso y una vez funcione todo usa el set completo*"],"metadata":{"id":"Ki3ULd3FBU8l"}},{"cell_type":"code","source":["epoch_array=[]\n","total_test_loss_array = [] \n","total_train_loss_array = []\n","total_test_loss = 0\n","show_plot = False\n","save_plot = False\n","test_step = 500\n","verbose = False\n","save_step = 1\n","\n","\n","#crea aquí las funciones test(), train() y save_params()"],"metadata":{"id":"IDevHmNuCzGx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.3.2 Responde las siguientes preguntas:\n","*  ¿Qué representa cada elemento de *X* en la función de *train()*?\n","*  ¿Qué se está usando como *label* para cada elemento de *X*? \n","*  Justifica el uso de *categorical_crossentropy* como función de loss\n","*  ¿Qué crees que está aprendiendo la red?\n","\n","\n","\n","\n"," "],"metadata":{"id":"P7byp9y1_00y"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"SjoEPKL7Cp9Z"}},{"cell_type":"markdown","source":["2.3.3 Entrena la red usando las funciones anteriores"],"metadata":{"id":"Jzu-37C4EKom"}},{"cell_type":"code","source":[""],"metadata":{"id":"gS16GEJaCrLH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##2.4 Comparación de modelos [2 pts]"],"metadata":{"id":"CkpRym4eFnN9"}},{"cell_type":"markdown","source":["En este último paso compararemos diferentes modelos. En la carpeta *models/chords* encontrarás los datos (en un formato similar al generado anteriormente) del entrenamiento de modelos similares con otros parámetros:\n","\n","1.   carpeta: 2717-Shifted_True_...\n","2.   carpeta: 5102-Shifted_True_...\n","\n"],"metadata":{"id":"FhwHC5ZJF0YW"}},{"cell_type":"markdown","source":["2.4.1 Compara los 3 modelos: grafica las funciones de loss para train y test de cada modelo.\n","\n","*   Indica los parámetros de cada uno de los 3 modelos (el que habéis entrenado y los 2 que os hemos dado)\n","*   ¿Qué set de parámetros ha dado la mejor performance?\n","*   ¿Se aprecia overfitting en alguno de los modelos? Justifica tu respuesta"],"metadata":{"id":"ab531tCvGhI3"}},{"cell_type":"code","source":[""],"metadata":{"id":"BEsa5EA2C-jQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 Análisis de la capa de embedding [2 pts]"],"metadata":{"id":"kEWwrLqnIhlz"}},{"cell_type":"markdown","source":["En esta sección recrearemos la figura 8 del artículo con la red que hemos entrenado y la que mejor performance nos ha dado en la comparación. "],"metadata":{"id":"H01zsudCIuTg"}},{"cell_type":"code","source":["from keras.models import load_model\n","import keras\n","from keras import backend as K"],"metadata":{"id":"jn_xE9QDJoMz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.1 Carga de modelos entrenados y generación de embeddings [1 pts]"],"metadata":{"id":"p0wEHRWAJ-ni"}},{"cell_type":"markdown","source":["3.1.1 Utiliza el *load_model* de **keras** para cargar:\n","*   el modelo que hemos entrenado: *my_model*\n","*   el modelo con mejor performance: *bp_model*\n"],"metadata":{"id":"GVFaCsSrKHLj"}},{"cell_type":"code","source":[""],"metadata":{"id":"j58DCb2YDBkJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.1.2 Ahora crearemos, para cada modelo, un nuevo modelo para los embedding. Para hacer esto, deberás crear un nuevo modelo cuya entrada sea igual a la entrada de los modelos originales y la salida sea el layer \"embedding\". Esto lo puedes hacer usando la función *get_layer()* del modelo.\n"],"metadata":{"id":"LvTrSPKTLxUO"}},{"cell_type":"code","source":[""],"metadata":{"id":"1Q5vhuS1DCYc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.1.3 El modelo de embedding recibe un acorde y devuelve un vector de 10 dimensiones con el embedding para cada acorde. Calcula estos vectores con cada uno de los modelos de embedding"],"metadata":{"id":"GVXc-FhGNfoP"}},{"cell_type":"code","source":[""],"metadata":{"id":"MNL05sWvDDZw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.1.4 Aplica un squeeze para eliminar los ejes de dimensión 1. El resultado de este squeeze debería ser (50,10)"],"metadata":{"id":"D33AZTgmO9u1"}},{"cell_type":"code","source":[""],"metadata":{"id":"S-keKk13DEXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 Análisis PCA [1 pts]\n"],"metadata":{"id":"_hQcmzeIPtrG"}},{"cell_type":"markdown","source":["Para acabar con nuestro análisis de los embeddings, vamos a realizar un proceso de PCA para reducir las dimensiones de los vectores resultantes y poder graficarlos en 2D."],"metadata":{"id":"2vMTJ8nRbmMe"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA"],"metadata":{"id":"l9ROxo-lP-OY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.2.1 Escalar los vectores y aplicar PCA para reducir a 2 las dimensiones"],"metadata":{"id":"0qcipt5oP74r"}},{"cell_type":"code","source":[""],"metadata":{"id":"1co2NuRtF1BU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.2.2 Grafica para ambos embeddings los vectores en un scatterplot. Añadele anotaciones con las notas del acorde y comenta el resultado: ¿Observas el efecto word2vect en las gráficas?"],"metadata":{"id":"Pj4FLd8DaLsF"}},{"cell_type":"code","source":[""],"metadata":{"id":"WSE2OSp9F2Va"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usa esta función para obtener un índice para los acordes y sus notas"],"metadata":{"id":"lJDmLqpebnkI"}},{"cell_type":"code","source":["def get_chord_dict():\n","    chord_to_index = pickle.load(open(dict_path + chord_dict_name, 'rb'))\n","    index_to_chord = pickle.load(open(dict_path + index_dict_name, 'rb'))\n","    return chord_to_index, index_to_chord\n","\n","chord_to_index, idx_2_chord = get_chord_dict()"],"metadata":{"id":"ROgMjNOmbbvK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.2.3 Crea una función para calcular todas las distancias entre los primero 20 acordes. Luego haz una lista con las 10 distancias mínimas para ambos modelos. ¿Están relacionados estos acordes con distancias mínimas?"],"metadata":{"id":"4TLRoLomVjzP"}},{"cell_type":"code","source":[""],"metadata":{"id":"FLHzUPP9F5UJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Rueda de 5tas (Bonus Track) [0.5 pts]"],"metadata":{"id":"PKXh0-X3mg70"}},{"cell_type":"markdown","source":["En este bonus track, y usando lo mismo que has usado para los apartados anteriores, podrás dibujar la rueda de quintas con datos entrenados sobre la misma base de datos, pero no hacer el shifteo de los acordes."],"metadata":{"id":"m3Ymmh_imljH"}},{"cell_type":"markdown","source":["Usa los datos que encontrarás en la carpeta *models/chords/9671-Shifted_False...* para repetir el proceso del análisis de PCA"],"metadata":{"id":"OyesH52p0QDZ"}},{"cell_type":"markdown","source":["Una vez tienes los vectores, llama a las siguientes funciones para dibujar la rueda de quintas"],"metadata":{"id":"ejP3t2sautBj"}},{"cell_type":"code","source":["def get_chord_dict_no_shifted():\n","    chord_to_index = pickle.load(open('data/chord_dict.pickle', 'rb'))\n","    index_to_chord = pickle.load(open('data/index_dict.pickle', 'rb'))\n","    return chord_to_index, index_to_chord\n","\n","chord_to_index_, idx_2_chord_ = get_chord_dict_no_shifted()"],"metadata":{"id":"_7ZU_OXZnxqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ddd={tuple((0,4,7)):'C',\n","tuple((1,5,8)):'C#',\n","tuple((2,6,9)):'D',\n","tuple((3,7,10)):'D#',\n","tuple((4,8,11)):'E',\n","tuple((0,5,9)):'F',\n","tuple((1,6,10)):'F#',\n","tuple((2,7,11)):'G',\n","tuple((0,3,8)):'G#',\n","tuple((1,4,9)):'A',\n","tuple((2,5,10)):'A#',\n","tuple((3,6,11)):'B'}\n","\n","\n","def plot_5th_circle(X_chords_2d):\n","  \n","  fig, ax = plt.subplots()\n","  fig.set_size_inches(8, 6)\n","\n","  plt.tick_params(labelsize=12)\n","  \n","  style = dict(size=12, color='black')\n","\n","  for i in range(0,len(idx_2_chord_)):\n","    try:\n","      ax.text(-X_chords_2d[i,0]-0.32,X_chords_2d[i,1]+0.11, ddd[idx_2_chord_[i]],**style)\n","      ax.scatter(-X_chords_2d[i,0],X_chords_2d[i,1], c=\"blue\", marker=\"*\")\n","      \n","    except:\n","      pass\n","\n","  plt.show()"],"metadata":{"id":"oTiU7UWtpnL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_5th_circle(my_embedd_pca) #pasa los vectores luego del análisis de PCA"],"metadata":{"id":"mGBGU7LruOes"},"execution_count":null,"outputs":[]}]}